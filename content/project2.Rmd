---
title: "Project 2"
author: "SDS348"
date: ""
output:
  html_document: default
  pdf_document: default
---

```{r global_options, include=FALSE}
#LEAVE THIS CHUNK ALONE!
library(knitr)
opts_chunk$set(fig.align="center", fig.height=5, message=FALSE, warning=FALSE, fig.width=8, tidy.opts=list(width.cutoff=60),tidy=TRUE)

class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
```

Bibiana Toro, bmt897

  My dataset looks at information collected on Covid-19 throughout different counties in Texas. My variables include the counties themselves but also total Covid-19 positive cases and fatalities in each county. It also includes the population numbers for each county included, and whether they are considered Metro or non-Metro. Any county that is part of an MSA is classified as a metro area regardless of its own size. A number of low population counties in Texas are considered metro areas because they are adjacent to larger population cores and share social and economic integration with the core. I also have a variable that includes the county's urban classification. An urban-rural designation developed by the National Center for Health Statistics.The most recent classification scheme was developed in 2013.I have a total of 198 observations for every variable, on e for every county. 

  This data is up to April 20th which is when I downloaded the numbers that the state provides, but they do update weekly. Also something to note is that this are not all the counties in Texas, only the counties that had positive cases of covid-19 as of April 20th. I picked this data because I thought that it would be interesting to look at something that is so relevant right now. I was also curious as how the different counties and there fore cities affect the prevalence of testing and coronavirus. 

```{R}
project2dataR<- read.csv("project2dataR.csv") 
project2dataR$Cumulative_Total_Test<-gsub(",", "", as.character(project2dataR$Cumulative_Total_Test))
head(project2dataR$Cumulative_Total_Test, 15)
project2dataR$Cumulative_Total_Test<-as.numeric(project2dataR$Cumulative_Total_Test)
library(ggplot2)
library(dplyr)

ggplot(project2dataR, aes(x = Positive, y = Cumulative_Total_Test)) +
geom_point(alpha = .5) + geom_density_2d(h=2) + coord_fixed() + facet_wrap(~NCHS_Urban_Rural_Classification )

covmats<-project2dataR%>%group_by(NCHS_Urban_Rural_Classification)%>%do(covs=cov(.[2:3]))
for(i in 1:3){print(as.character(covmats$NCHS_Urban_Rural_Classification[i])); print(covmats$covs[i])}

man1<-manova(cbind(Positive, Cumulative_Total_Test, Fatalities)~NCHS_Urban_Rural_Classification , data=project2dataR)
summary(man1) ####Manova is significant
summary.aov(man1)

project2dataR%>%group_by(NCHS_Urban_Rural_Classification )%>%summarize(mean(Positive), mean(Fatalities), mean(Cumulative_Total_Test))

pairwise.t.test(project2dataR$Positive,
project2dataR$NCHS_Urban_Rural_Classification, p.adj="none")

pairwise.t.test(project2dataR$Cumulative_Total_Test,
project2dataR$NCHS_Urban_Rural_Classification, p.adj="none")

pairwise.t.test(project2dataR$Fatalities,
project2dataR$NCHS_Urban_Rural_Classification, p.adj="none")

###type I error
1-.95^3
```
  The assumptions made for Manova are they are random samples and independent observations. I would say that the data set is random because it is data collected throughout all counties with positive cases of Covd-19, and they would be independent because the collection is not based on anything.A one-way MANOVA was conducted to determine the effect of the NCHS_Urban_Rural_Classification on three dependent variables (all numeric-Positive, Fatalities, Cumulative_Total_Test).I tried to analyze the bivariate density plots for each group and I concluded that they revealed no stark deparures from multivariate normality. Examination of the covariance matrices for each group showed relative homogeneity. No univariate or multivariate outliers were evident and MANOVA was considered to be an appropriate analysis technique.
  Significant difference was found between Positive, Fatalities, Total Cumulative Tests, and the Urban Classification because their p-values were all less than 0.05. Because of this, I went on to perform a an Anova to find the mean differences among the groups. From these differences it was interesting to see the big difference in positive cases between Large Central Metro and Non-Core. These numbers make sense, because you would expect to see bigger means in the largets metros vs the Micro and Non Core. I also perfromed 3 post-hoc tests to see which groups differ. Since we did 3 post-hoc tests, the probabilty of a type one error is 14.2625%. To keep the type one error at 0.5, I divided 0.05/3= 0.01667.(bonferroni correction) Using these boundaries, I found that that all three dependent variables are significantly different when you look at the Large Central compared to other values, and non-core category. 


```{R}
library(vegan)
dists<-project2dataR%>%select(Fatalities, Positive, Cumulative_Total_Test)%>%dist()
adonis(dists~NCHS_Urban_Rural_Classification,data=project2dataR)


SST<- sum(dists^2)/150
SSW<-project2dataR%>%group_by(NCHS_Urban_Rural_Classification)%>%select(Fatalities, Positive, Cumulative_Total_Test)%>%
do(d=dist(.[2:3],"euclidean"))%>%ungroup()%>%
summarize(sum(d[[1]]^2)/50 + sum(d[[2]]^2)/50+ sum(d[[3]]^2)/50)%>%pull
F_obs<-((SST-SSW)/2)/(SSW/147) #observed F statistic




# compute null distribution for F
Fs<-replicate(1000,{
new<-project2dataR%>%mutate(NCHS_Urban_Rural_Classification=sample(NCHS_Urban_Rural_Classification)) #permute the species vector
SSW<-new%>%group_by(NCHS_Urban_Rural_Classification)%>%select(Fatalities, Positive, Cumulative_Total_Test)%>%
do(d=dist(.[2:3],"euclidean"))%>%ungroup()%>%
summarize(sum(d[[1]]^2)/50 + sum(d[[2]]^2)/50+ sum(d[[3]]^2)/50)%>%pull
((SST-SSW)/2)/(SSW/147) #calculate new F on randomized data
})

hist(Fs,prob = T); abline(v=F_obs, col="red")

mean(Fs>F_obs)
```

  Our null hypothesis becomes that there is no difference between the group means. When I do a randomization test, I find that the difference in F statistic between non-ranodmized and ranodmized data is 0.54. This p value is small enough to reject the null hypothesis which means that there is a difference between the groups. 
```{R}
library(sandwich)
library(lmtest)
library(ggplot2)
project2dataR$Positive_c <- project2dataR$Positive  - mean(project2dataR$Positive)
project2dataR$Fatalities_c <- project2dataR$Fatalities  - mean(project2dataR$Fatalities)
fit<-lm(Positive_c~ Metro_vs_Non_Metro+ Fatalities_c, data=project2dataR)
summary(fit)
fit2<-lm(Positive_c ~ Metro_vs_Non_Metro*Fatalities_c , data=project2dataR)
summary(fit2)

ggplot(project2dataR, aes(x=Positive_c, y=Fatalities_c,group=Metro_vs_Non_Metro))+geom_point(aes(color=Metro_vs_Non_Metro))+
geom_smooth(method="lm",se=F,fullrange=T,aes(color=Metro_vs_Non_Metro))+
theme(legend.position=c(.9,.19))+xlab("")+ggtitle("Linear Regression")


ggplot(project2dataR, aes(Positive_c, Fatalities_c)) +
geom_point(alpha=.9)+theme_bw()
 ###Homoestacity and normalicy

resids<-fit$residuals
fitvals<-fit$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')

ggplot()+geom_histogram(aes(resids),bins=10)


##SE
coeftest(fit)[,1:2]
coeftest(fit, vcov = vcovHC(fit))[,1:2]



```
  In our linear regression, we make the following assumptions: linear relationship between x and y, randomization, equal variance, and normal distribution. From our first regression, fit, we can see that controlling for Metro vs Non Metro, Fatalities do explain variations in positives. However, Controlling for Fatalities, Metro vs Non Metro does not explain positives. This was very surprising to me. Because I would think that Metro areas would affect the number of positive cases of Covid-19. If you do a second regression of interactions, then one finds that there was no sense of variation of Positives. This is based on looking at coefficients for p vales that are less than 0.05. The analysis above can also be seen the ggplot that shows an upward slope, which would imply that there is a variation present. There wasn't much difference between the SE and Robust SE from what I calculated. The proportion of variation of my ourcome that my model explains is 0.8598. I found this information from the Multiple R squared value from the summary(fit2) function. 


```{R}

###bootstrap standard errors

samp_distn<-replicate(5000, {
boot_dat <- sample_frac(project2dataR, replace=T) #bootstrap your data
fit3 <- lm(Positive_c ~ Metro_vs_Non_Metro*Fatalities_c , data=boot_dat) #fit model
coef(fit3) #save coefs
})



```

There was a big differece between my original SE and the bootstrap SE that I just calculated. It makes sense that they decreased, because since R studio is using a sampling distribution, the results should be closer to the actual numbers. 


```{R}
library(tidyverse)
library(lmtest)

data<-project2dataR%>%mutate(y=ifelse(Metro_vs_Non_Metro=="Metro",1,0))
data$Metro_vs_Non_Metro<-factor(data$Metro_vs_Non_Metro,levels=c("Metro","Non-Metro"))
head(data)

fit4<-glm(y~Positive+Fatalities, data=data, family="binomial")
coeftest(fit4)

#log-odds scale coefs (additive)
coef(fit4)%>%round(5)%>%data.frame
#odds scale coefs (multiplicative)
coef(fit4)%>%exp%>%round(5)%>%data.frame

probs<-predict(fit4,type="response") 
table(predict=as.numeric(probs>.5),truth=data$y)%>%addmargins

##Sensitivity
42/79

###Specificity
111/119

###precision
42/50

##accuracy
(111+42)/198

###log-odds plot
data$logit<-predict(fit4,type="link")

data%>%ggplot()+geom_density(aes(logit,color=Metro_vs_Non_Metro,fill=Metro_vs_Non_Metro), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=Metro_vs_Non_Metro))+
  geom_text(x=-5,y=.07,label="TN = 431")+
  geom_text(x=-1.75,y=.008,label="FN = 19")+
  geom_text(x=1,y=.006,label="FP = 13")+
  geom_text(x=5,y=.04,label="TP = 220")+scale_x_log10()+ggtitle("Log-odds Plot")


###ROC
library(plotROC)
ROCplot<-ggplot(project2dataR)+geom_roc(aes(d=Metro_vs_Non_Metro, m=Positive+Fatalities), n.cuts=0)
ROCplot
calc_auc(ROCplot)

###10-fold CV
set.seed(1234)
k=10
data2<- project2dataR %>% sample_frac 
folds <- ntile(1:nrow(data2),n=10) 
diags<-NULL
for(i in 1:10){
train <- data2[folds!=i,]
test <- data2[folds==i,] 
truth <- test$Metro_vs_Non_Metro
fit5<- glm(Metro_vs_Non_Metro~Positive+Fatalities,data=train,family="binomial")
probs <- predict(fit5, newdata=test, type="response")
diags<-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)


```

  For this analysis, I used Non Metro vs Metro for my binary variable. In this case, I made Metro 1 and Non Metro 0. The coefficients showed me that the Positive Cases due contribute to Variation in Mtero vs Non Metro; however, fatalities do not. This is a bit different from the analysis from the previous regression, but that involved multiple subdivions of urban classification not just 2. I think that might be where the difference between the two linear regressions is coming from. The sensitivity that I calculated is that the sensitivity is 0.5316456. The specificity is 0.9327731, the precision is 0.84, and the accuracy is 0.7727273. This helps us identify the the true positive rate, the true negative rate, and the proportion of actual metro data. 
  The ROC curve I generated, treats Metro as 0 and Non-Metro as 1. The AUC calculated is 0.2159345. This is a very poor AUC, which means that the our plot is not very demonstrative of my data, because AUC usually means the probability that the model will randomly draw a  positive sample higher than a randomly drawn negative sample. 
  The following numbers: 0.7573684,0.9241142,0.5047619,0.7414336	0.7686583. The previous are the diagnostics of AAC, SENS, SPEC, PPV, AUC. This is a much better AUC, which might have to do with the fact that it is a 10 fold or repeated sampling which is supposed to make your plot more represenative of your data, because it has a lower variance. 



```{R}
###Lasso
library(dplyr)
library(glmnet)
new_data<-project2dataR%>%select(-"County", -"Positive_c", -"Fatalities_c")
y<-as.matrix(new_data$Positive) 
x<-model.matrix(Positive~.,new_data)[,-1] 
head(x)
x<-scale(x)
cv<-cv.glmnet(x,y) 


{plot(cv$glmnet.fit, "lambda", label=TRUE)
abline(v = log(cv$lambda.1se))
abline(v = log(cv$lambda.min),lty=2)}

lasso1<-glmnet(x,y,lambda=cv$lambda.1se)
coef(lasso1)


##10-fold
set.seed(1234)
k=10 #choose number of folds
data4<-new_data[sample(nrow(new_data)),] #randomly order rows
folds2<-cut(seq(1:nrow(new_data)),breaks=10,labels=F) #create folds
diags2<-NULL
for(i in 1:k){
## Create training and test sets
train2<-data4[folds!=i,]
test2<-data4[folds==i,]
truth2<-test2$Positive
## Train model on training set
fit6<-glm(Metro_vs_Non_Metro~.,data=train2,family="binomial")
probs3<-predict(fit6,newdata = test2,type="response")
## Test model on test set (save all k results)
diags4<-rbind(diags2,class_diag(probs3,truth2))
}
diags4%>%summarize_all(mean)

```

  The variables that were kept were the following:Fatalities, Cumulative Total Test, Population, and the NCHS Urban Rural Classification. The new AUC that I got is 1 which is much better than 0.76 from above, because one means that the our plots are representative of our data. The higher the AUC means that our model is better at predicting 0s and 1s. 



```{R, echo=F}
## DO NOT DELETE THIS CHUNK!
sessionInfo()
Sys.time()
Sys.info()
```